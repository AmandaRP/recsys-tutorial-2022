---
title: "Tutorial:<br>Recommender Systems"
author: "Amanda Peterson"
date: May 20, 2022
format: 
  revealjs:
    scrollable: false
    chalkboard: true
    #theme: dark
    footer: "SCADS 2022 RecSys Tutorial"
    navigation-mode: linear
    transition: slide
    background-transition: fade
    #logo: "images/thumb.png"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Outline

</br>

- Definitions
- Overview of "traditional" collaborative filtering & hybrid models
- Deep learning for recommendation
- News recommendations
- Evaluation metrics
- Hands-on exercise

## Types of Recommender Systems

::: {.panel-tabset}

### Collaborative Filtering 

Model patterns across all users' [feedback history]{.underline}.

-   **Pro**: Perform better than content filtering models when collaborative information is available.

-   **Con**: Unable to make recommendations in [cold start]{.underline} scenarios where little history is available for new users or items.

### Content Filtering

Individualized models focus on a single user's feedback history (or a group of like users) + metadata associated with items.

-   **Pro**: Able to handle new items.

-   **Cons**: Models for each user (or group) are fit in isolation. Require large amounts of data for each user.

### Hybrid

Collaborative + Content Filtering

-   **Pro**: Overcomes challenges of both types of filtering. User *and* item metadata (aka [side information]{.underline}) can be included.

:::

## More Definitions

**Explicit Feedback** **(or rating)**: Explicit rating given by the user for a product (e.g. star rating, thumbs up/down)

![](images/star_rating.jpg) 

**Implicit Feedback**: Actions taken by the user which can be used infer preferences about products (e.g. click data, dwell time, purchases)

## User-item Rating Array {transition="slide-in none-out"}

![](images/user_item_matrix.png)


## User-item Rating Array (Implicit) {transition="none"}

![](images/user_item_matrix_implicit.png)

## Data Sparsity

Data used to learn recommendations is notoriously sparse. 

Examples:

- [MovieLens 25K](https://grouplens.org/datasets/movielens/): 99.75% sparse
- [Micrsoft News Dataset](https://msnews.github.io/): 99.98% sparse
- [Amazon](https://cseweb.ucsd.edu//~jmcauley/pdfs/www16a.pdf): > 99.99% sparse

## Dimension Reduction of the User-item Array

## User-Item Array as a Bipartite Graph

![Items represented as blue nodes (bottom). Users represented as pink nodes (top). User-item interactions represented by an edge. Edges colored according to a particular user feature.](images/bipartite.png)

## Recommender Technology Timeline {transition="slide-in none-out" auto-animate=true}

![](images/nick_pentreath_timeline.png) 

[Presentation by Nick Pentreath at the 2018 Spark + AI Summit](https://youtu.be/y_TzOOCJqxI)

**2017 - 2022**: Advances in deep learning for recommender systems.

## {transition="none" auto-animate=true}

![](images/nick_pentreath_timeline.png){fig-align="center" width=70%} 

![](images/red_arrow.png){.absolute top=25 left=110 width="50" height="25"}

**Item-item similarity**: Can be computed using cosine or Jaccard similarity, for example.

![](images/user_item_matrix_item_sim.png){fig-align="center" width=30%}



## {transition="none" auto-animate=true}

![](images/nick_pentreath_timeline.png){fig-align="center" width=70%} 


![](images/red_arrow.png){.absolute top=150 left=220 width="50" height="25"}


![](images/netflix_fig2.png){fig-align="center" width=40%}

::: aside

[Matrix Facorization Techniques for Recommender Systems](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.147.8295&rep=rep1&type=pdf) by Koren, Bell, and Volinsky

:::


## {transition="none" auto-animate=true}


![](images/nick_pentreath_timeline.png){fig-align="center" width=70%}

![](images/red_arrow.png){.absolute top=25 left=360 width="50" height="25"}

![](images/factorization_machine.png){fig-align="center" width=75%}

## 

<br>

::: r-fit-text
**Deep Learning Models<br>for Recommender Systems** 
:::

## Matrix Factorization in a Deep Learning Framework

:::: {.columns}

::: {.column width="50%"}

![](images/matrix_factorization.png){fig-align="center"  height=350}
:::
::: {.column width="50%"}

- Use sigmoid prediction function and binary cross-entropy (log loss) for binary feedback
- Use linear regression prediction function and MSE loss for 5-star ratings

:::
::::

## Wide and Deep

:::: {.columns}

::: {.column width="60%"}
![](images/wide_and_deep.png){height=300 fig-alight='center'}
:::

::: {.column width="40%"}

- Model from Google 
- Memorization + Generalization
- Example: 

:::
::::

::: aside

[Wide & Deep Learning for Recommender Systems](https://arxiv.org/pdf/1606.07792.pdf). 2016. Heng-Tze Cheng et. al. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (DLRS 2016). Association for Computing Machinery. 

:::



## NCF


:::: {.columns}

::: {.column width="50%"}
![](images/ncf.png){height=350}
:::

::: {.column width="50%"}
- Previous RecSys Model for [MLPerf](https://www.nvidia.com/en-us/data-center/resources/mlperf-benchmarks/#:~:text=MLPerf%20is%20a%20consortium%20of,all%20conducted%20under%20prescribed%20conditions.)
- Collaborative filtering only (no side features)

:::

::::

::: aside

[Neural Collaborative Filtering](https://arxiv.org/pdf/1708.05031.pdf). 2017. Proceedings of the 26th International Conference on World Wide Web. Xiangnan He et. al.

:::



## DeepFM

:::: {.columns}

::: {.column width="60%"}
![](images/deepfm.png){height=350}
:::

::: {.column width="40%"}
- Model from Huawei
- Example: 

:::

::::

::: aside

[DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](https://www.ijcai.org/proceedings/2017/0239.pdf). 2017. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence.  (IJCAI-17). Huifeng Guo et. al.

:::


## DLRM

:::: {.columns}

::: {.column width="60%"}
![](https://gitlab.evoforge.org/arpete2/dlrs-catalog/-/raw/main/images/DLRM.png){height="350" fig-align="center"}
:::

::: {.column width="40%"}
- Model from Facebook
- Current [MLPerf](https://www.nvidia.com/en-us/data-center/resources/mlperf-benchmarks/#:~:text=MLPerf%20is%20a%20consortium%20of,all%20conducted%20under%20prescribed%20conditions.) RecSys model

:::

::::



::: aside
[Deep Learning Recommendation Model for Personalization and Recommendation Systems](https://arxiv.org/abs/1906.00091). 2019. arXiv. Maxim Naumov et. al. 
:::




## DCNV2

:::: {.columns}

::: {.column width="60%"}
![](images/dcnv2.png){height="400"}
:::

::: {.column width="40%"}
- Model from Google
- Parallel and stacked versions
- Cross Network: $x_{i+1} = x_0 (Wx_i + b) + x_i$

:::

::::

::: aside

[DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems](https://arxiv.org/pdf/2008.13535.pdf). 2021. In Proceedings of the Web Conference 2021 (WWW '21). Association for Computing Machinery. Ruoxi Wang et. al.

:::


## Explainability of DCN-V2 

We can consider the weight matrix W in the first cross
layer.

![DCN-V2: Visualization of learned weight matrix in DCN-V2.
Rows and columns represents real features. For (a), feature
names were not shown for proprietary reasons; darker pixel
represents larger weight in its absolute value. Orange boxes 
highlight notable feature crosses. For (b), each
block represents the Frobenius norm of each matrix block.](images/explain.png){height=300}

::: {.notes}
From the DCN-V2 paper: "The off-diagonal block corresponds to crosses that are known to be important, suggesting the effectiveness of DCN-V2. The diagonal 
block represents selfinteraction ($x^2$'s). Subplot (b) shows each blockâ€™s Frobenius norm and indicates some strong interactions learned, 
e.g., Gender x UserId, MovieId x UserId."
:::


## Additional Reading: Explainability of Deep Learning RecSys Models


## "Two-tower" Sysetms


## Additional Reading: Deep Learning for RecSys



## 

<br><br>

::: r-fit-text
**News Recommendation**
:::

## MIND

<br><br>

We're working with the **Mi**crosoft **N**ews **D**ataset this summer! 

::: aside

The paper is available at [https://aclanthology.org/2020.acl-main.331.pdf](https://aclanthology.org/2020.acl-main.331.pdf).

:::

## Challenges of News Recommendation {transition="slide-in none-out"}

(@) **Severe cold start problem**: New articles posted continuously. Usefulness of articles diminishes quickly. 

:::: {.columns}

::: {.column width="40%"}
![Survival time distribution of news articles](images/survival_mind.png){fig-align='left'}
:::

::: {.column width="60%"}
- Survival time of more than 84.5% news
articles is less than two days.
- Estimated using the time interval between
first and last appearance time of articles in the MIND dataset.
:::

::::

::: aside
Image sourced from the [MIND paper](https://aclanthology.org/2020.acl-main.331.pdf).
:::



## Challenges of News Recommendation {transition="none"}

(@) A user may get bored by a news feed with **lack of diversity**. Articles from a variety of topics may be more interesting.
(@) **Overly personalized** news feeds give can give a narrow view of the world.

The last point can be a result of over-emphasis on prediction accuracy. Beyond-accuracy metrics may help.


## NRMS

:::: {.columns}

::: {.column width="60%"}

![](images/nrms.png)
:::

::: {.column width="40%"}

* Model from Microsoft
* Best performing model in the [MIND paper](https://aclanthology.org/2020.acl-main.331.pdf).

:::
::::

::: aside
[Neural News Recommendation with Multi-Head Self-Attention](https://wuch15.github.io/paper/EMNLP2019-NRMS.pdf). 2019. Wue et. al.
:::

## The MIND Challenge

## Further Reading

## Other Types of RecSys Models

- Recurrent Neural Networks
- Networks for Knowledge Graphs

::: aside
[A Comprehensive Survey of Knowledge Graph-Based
Recommender Systems: Technologies, Development,
and Contributions](https://doi.org/10.3390/info12060232). 2021. Chicaiza and Valdiviezo-Diaz. MDPI Information journal.
:::


## 

<br><br><br>

::: r-fit-text
**Evaluation of RecSys Models**
:::

## Evaluation Metrics for Recommendation Systems

![](images/evalrs.png){.absolute top=0 left=800 width="180" height="200"}

::: {.panel-tabset}


### Accuracy 

::: {.incremental}
  - Hit Rate at k (HR@k)
  - Mean Average Precision at k (MAP@k)
  - Normalized Discounted Cumulative Gain (NDCG@k)
  - Mean Reciprocal Rank (MRR)
:::
  
### Beyond accuracy

::: {.incremental}
  - Diversity at k (Div@k)
  - Novelty at k (Nov@k)
  - Catalog coverage (CC)
:::

:::


# Final Thoughts

## Tricks of the Trade

- **Sampling negative examples**: Weight items by popularity. This will better penalize popular items that can be recommended 
- **Ranking vs retrieval**: If there are too many items to score, run a query to obtain a user's "candidate" recommended items. Use RecSys model to rank the candidates..

## More Tips

Personalized recommendations in conjunction with other types of recommendations can provide a more satisfying experience.

![](images/ui_sketch.png){fig-align='center'}

![](images/red_arrow.png){.absolute top=507 left=355 width="50" height="25"}



## Advice

*Are we really making much progress? A worrying analysis of recent neural recommendation approaches.*

- Make code/analysis/tuning/data reproducible. 
- Use as many baseline algorithms as possible (including non-NN)
- Use as many metrics as possible (some are better than others for different tasks)


## Code 

- Microsoft GitHub Repo: https://github.com/microsoft/recommenders
- Tensorflow: https://www.tensorflow.org/recommenders
- R Keras: https://github.com/AmandaRP

## 

::: {.r-fit-text}
Questions?
:::

<center>

Slides are available at: TODO

</center>